{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3969/3969 [00:09<00:00, 400.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 441/441 [00:01<00:00, 410.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Value Counts\n",
      "0    1368\n",
      "1    1368\n",
      "2    1233\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Test Value Counts\n",
      "0    152\n",
      "1    152\n",
      "2    137\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "X Train Shape\n",
      "(3969, 150, 150, 3)\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "X Test Shape\n",
      "(441, 150, 150, 3)\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np \n",
    "import cv2\n",
    "from keras.preprocessing import image \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from skimage.segmentation import mark_boundaries \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_image_value(path, dim): \n",
    "    '''This function will read an image and convert to a specified version and resize \n",
    "    depending on which algorithm is being used. '''\n",
    "    img = image.load_img(path, target_size = dim)\n",
    "    img = image.img_to_array(img)\n",
    "    return img/255\n",
    "\n",
    "def get_img_array(img_paths, dim): \n",
    "    '''This fucntion takes a list of image paths and returns the np array corresponding to each image.  \n",
    "    It also takes the dim and whether edge is specified in order to pass it to another function to apply these parameters.  \n",
    "    This function uses get_image_value to perform these operations'''\n",
    "    final_array = []\n",
    "    from tqdm import tqdm\n",
    "    for path in tqdm(img_paths):\n",
    "        img = get_image_value(path, dim)\n",
    "        final_array.append(img)\n",
    "    final_array = np.array(final_array)  \n",
    "    return final_array\n",
    "\n",
    "def get_tts():\n",
    "    '''This function will create a train test split'''  \n",
    "   \n",
    "    DIM =  (150,150) \n",
    "    np.random.seed(10)        \n",
    "    pistol_paths = [path + 'Pistol//' + i for i in os.listdir(path + 'Pistol')] \n",
    "    pistol_labels = [1 for i in range(len(pistol_paths))]\n",
    "    rifle_paths = [path + 'Rifle//' + i  for i in os.listdir(path + 'Rifle')] \n",
    "    rifle_labels = [2 for i in range(len(rifle_paths))]    \n",
    "    neg_paths = [path + 'NoWeapon//' + i for i in os.listdir(path + 'NoWeapon')]\n",
    "    np.random.shuffle(neg_paths)\n",
    "    neg_paths = neg_paths[:len(pistol_paths)- 500]\n",
    "    neg_labels = [0 for i in range(len(neg_paths))]\n",
    "\n",
    "    np.random.shuffle(pistol_paths)\n",
    "    pistol_paths = pistol_paths[:len(rifle_paths)+150]\n",
    "    neg_paths = neg_paths[:len(rifle_paths)+150]\n",
    "\n",
    "    pistol_labels = [1 for i in range(len(pistol_paths))]\n",
    "    rifle_labels = [2 for i in range(len(rifle_paths))]\n",
    "    neg_labels = [0 for i in range(len(neg_paths))]\n",
    "    paths = pistol_paths + rifle_paths + neg_paths\n",
    "#     paths = pistol_paths \n",
    "    \n",
    "#     labels =  pistol_labels \n",
    "    labels = pistol_labels + rifle_labels + neg_labels\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(paths, labels, stratify = labels, train_size = .90, random_state = 10)\n",
    "\n",
    "    new_x_train = get_img_array(x_train, DIM)\n",
    "    new_x_test = get_img_array(x_test, DIM)\n",
    "    \n",
    "    print('Train Value Counts')\n",
    "    print(pd.Series(y_train).value_counts())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('Test Value Counts')\n",
    "    print(pd.Series(y_test).value_counts())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('X Train Shape')\n",
    "    print(new_x_train.shape)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('X Test Shape')\n",
    "    print(new_x_test.shape)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    y_test = to_categorical(y_test)\n",
    "    y_train = to_categorical(y_train)\n",
    "    tts = (new_x_train, new_x_test, y_train, y_test)\n",
    "    return tts\n",
    "\n",
    "path = 'D:/OneDrive - CGIAR/PROYECTOS/Croppie/Tutoriales/Separated/FinalImages/'\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_tts()\n",
    "\n",
    "#uncomment the code below to see what the images look like\n",
    "#cv2.imshow('test', x_train[25])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment the code below to see what the images look like\n",
    "cv2.imshow('test', x_train[44])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "#from keras.models import Sequential\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,  BatchNormalization, AveragePooling2D, Dense, Dropout, Flatten \n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import cv2\n",
    "\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_conv_model(dim = (150,150, 3)):\n",
    "    '''This function will create and compile a CNN given the input dimension'''\n",
    "    inp_shape = dim\n",
    "    act = 'relu'\n",
    "    drop = .25\n",
    "    kernal_reg = regularizers.l1(.001)\n",
    "    optimizer = Adam(lr = .0001)    \n",
    "    model = Sequential() \n",
    "    model.add(Conv2D(64, kernel_size=(3,3),activation=act, input_shape = inp_shape, \n",
    "                     kernel_regularizer = kernal_reg,\n",
    "                     kernel_initializer = 'he_uniform',  padding = 'same', name = 'Input_Layer'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),  strides = (3,3)))\n",
    "    model.add(Conv2D(64, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3))) \n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3)))  \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(3, activation='softmax', name = 'Output_Layer'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 11.3341 - accuracy: 0.5348\n",
      "Epoch 00001: val_loss improved from inf to 10.25967, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 88s 705ms/step - loss: 11.3339 - accuracy: 0.5346 - val_loss: 10.2597 - val_accuracy: 0.6712\n",
      "Epoch 2/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 9.4761 - accuracy: 0.6507\n",
      "Epoch 00002: val_loss improved from 10.25967 to 8.68995, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 90s 721ms/step - loss: 9.4757 - accuracy: 0.6508 - val_loss: 8.6899 - val_accuracy: 0.6599\n",
      "Epoch 3/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 8.0262 - accuracy: 0.6928\n",
      "Epoch 00003: val_loss improved from 8.68995 to 7.51532, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 89s 715ms/step - loss: 8.0261 - accuracy: 0.6926 - val_loss: 7.5153 - val_accuracy: 0.6213\n",
      "Epoch 4/1000\n",
      "125/125 [==============================] - ETA: 0s - loss: 6.8792 - accuracy: 0.7274\n",
      "Epoch 00004: val_loss improved from 7.51532 to 6.49302, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 89s 714ms/step - loss: 6.8792 - accuracy: 0.7274 - val_loss: 6.4930 - val_accuracy: 0.6349\n",
      "Epoch 5/1000\n",
      "125/125 [==============================] - ETA: 0s - loss: 5.9525 - accuracy: 0.7455\n",
      "Epoch 00005: val_loss improved from 6.49302 to 5.68940, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 88s 703ms/step - loss: 5.9525 - accuracy: 0.7455 - val_loss: 5.6894 - val_accuracy: 0.6916\n",
      "Epoch 6/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 5.2572 - accuracy: 0.7639\n",
      "Epoch 00006: val_loss improved from 5.68940 to 5.02778, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 91s 729ms/step - loss: 5.2571 - accuracy: 0.7639 - val_loss: 5.0278 - val_accuracy: 0.7075\n",
      "Epoch 7/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 4.7490 - accuracy: 0.7724\n",
      "Epoch 00007: val_loss improved from 5.02778 to 4.59208, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 93s 741ms/step - loss: 4.7489 - accuracy: 0.7725 - val_loss: 4.5921 - val_accuracy: 0.7143\n",
      "Epoch 8/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 4.3519 - accuracy: 0.7891\n",
      "Epoch 00008: val_loss improved from 4.59208 to 4.29340, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 94s 752ms/step - loss: 4.3517 - accuracy: 0.7891 - val_loss: 4.2934 - val_accuracy: 0.7234\n",
      "Epoch 9/1000\n",
      "125/125 [==============================] - ETA: 0s - loss: 4.1003 - accuracy: 0.7795\n",
      "Epoch 00009: val_loss improved from 4.29340 to 4.13276, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 93s 744ms/step - loss: 4.1003 - accuracy: 0.7795 - val_loss: 4.1328 - val_accuracy: 0.6599\n",
      "Epoch 10/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 3.8895 - accuracy: 0.7923\n",
      "Epoch 00010: val_loss improved from 4.13276 to 3.86106, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 96s 764ms/step - loss: 3.8894 - accuracy: 0.7924 - val_loss: 3.8611 - val_accuracy: 0.7415\n",
      "Epoch 11/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 3.6599 - accuracy: 0.8120\n",
      "Epoch 00011: val_loss improved from 3.86106 to 3.78176, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 92s 736ms/step - loss: 3.6601 - accuracy: 0.8118 - val_loss: 3.7818 - val_accuracy: 0.7166\n",
      "Epoch 12/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 3.5271 - accuracy: 0.8054\n",
      "Epoch 00012: val_loss improved from 3.78176 to 3.62532, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 92s 735ms/step - loss: 3.5272 - accuracy: 0.8052 - val_loss: 3.6253 - val_accuracy: 0.7098\n",
      "Epoch 13/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 3.3552 - accuracy: 0.8188\n",
      "Epoch 00013: val_loss improved from 3.62532 to 3.39474, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 92s 734ms/step - loss: 3.3551 - accuracy: 0.8188 - val_loss: 3.3947 - val_accuracy: 0.7370\n",
      "Epoch 14/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 3.2129 - accuracy: 0.8203\n",
      "Epoch 00014: val_loss improved from 3.39474 to 3.25999, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 91s 730ms/step - loss: 3.2129 - accuracy: 0.8201 - val_loss: 3.2600 - val_accuracy: 0.7642\n",
      "Epoch 15/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 3.1077 - accuracy: 0.8148\n",
      "Epoch 00015: val_loss improved from 3.25999 to 3.21890, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 92s 736ms/step - loss: 3.1076 - accuracy: 0.8148 - val_loss: 3.2189 - val_accuracy: 0.7528\n",
      "Epoch 16/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 2.9627 - accuracy: 0.8319\n",
      "Epoch 00016: val_loss improved from 3.21890 to 3.03018, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 93s 741ms/step - loss: 2.9627 - accuracy: 0.8319 - val_loss: 3.0302 - val_accuracy: 0.7415\n",
      "Epoch 17/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 2.8566 - accuracy: 0.8347\n",
      "Epoch 00017: val_loss improved from 3.03018 to 2.98242, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 89s 713ms/step - loss: 2.8566 - accuracy: 0.8347 - val_loss: 2.9824 - val_accuracy: 0.7483\n",
      "Epoch 18/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 2.7423 - accuracy: 0.8448\n",
      "Epoch 00018: val_loss improved from 2.98242 to 2.85500, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 88s 703ms/step - loss: 2.7422 - accuracy: 0.8448 - val_loss: 2.8550 - val_accuracy: 0.7483\n",
      "Epoch 19/1000\n",
      "125/125 [==============================] - ETA: 0s - loss: 2.6433 - accuracy: 0.8443\n",
      "Epoch 00019: val_loss improved from 2.85500 to 2.77835, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 90s 717ms/step - loss: 2.6433 - accuracy: 0.8443 - val_loss: 2.7783 - val_accuracy: 0.7528\n",
      "Epoch 20/1000\n",
      "125/125 [==============================] - ETA: 0s - loss: 2.5478 - accuracy: 0.8536\n",
      "Epoch 00020: val_loss improved from 2.77835 to 2.68964, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 93s 747ms/step - loss: 2.5478 - accuracy: 0.8536 - val_loss: 2.6896 - val_accuracy: 0.7528\n",
      "Epoch 21/1000\n",
      "125/125 [==============================] - ETA: 0s - loss: 2.4644 - accuracy: 0.8571\n",
      "Epoch 00021: val_loss did not improve from 2.68964\n",
      "125/125 [==============================] - 94s 751ms/step - loss: 2.4644 - accuracy: 0.8571 - val_loss: 2.6977 - val_accuracy: 0.7302\n",
      "Epoch 22/1000\n",
      "125/125 [==============================] - ETA: 0s - loss: 2.3845 - accuracy: 0.8624\n",
      "Epoch 00022: val_loss improved from 2.68964 to 2.53203, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 103s 826ms/step - loss: 2.3845 - accuracy: 0.8624 - val_loss: 2.5320 - val_accuracy: 0.7551\n",
      "Epoch 23/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 2.3113 - accuracy: 0.8652\n",
      "Epoch 00023: val_loss improved from 2.53203 to 2.48857, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 99s 789ms/step - loss: 2.3112 - accuracy: 0.8652 - val_loss: 2.4886 - val_accuracy: 0.7619\n",
      "Epoch 24/1000\n",
      "125/125 [==============================] - ETA: 0s - loss: 2.2380 - accuracy: 0.8660\n",
      "Epoch 00024: val_loss did not improve from 2.48857\n",
      "125/125 [==============================] - 96s 768ms/step - loss: 2.2380 - accuracy: 0.8660 - val_loss: 2.5340 - val_accuracy: 0.7098\n",
      "Epoch 25/1000\n",
      "125/125 [==============================] - ETA: 0s - loss: 2.1995 - accuracy: 0.8539\n",
      "Epoch 00025: val_loss improved from 2.48857 to 2.39791, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 103s 821ms/step - loss: 2.1995 - accuracy: 0.8539 - val_loss: 2.3979 - val_accuracy: 0.7460\n",
      "Epoch 26/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 2.1042 - accuracy: 0.8742\n",
      "Epoch 00026: val_loss improved from 2.39791 to 2.31853, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 96s 770ms/step - loss: 2.1042 - accuracy: 0.8743 - val_loss: 2.3185 - val_accuracy: 0.7370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000\n",
      "124/125 [============================>.] - ETA: 0s - loss: 2.0491 - accuracy: 0.8775\n",
      "Epoch 00027: val_loss improved from 2.31853 to 2.28055, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 96s 767ms/step - loss: 2.0492 - accuracy: 0.8773 - val_loss: 2.2805 - val_accuracy: 0.7574\n",
      "Epoch 28/1000\n",
      "125/125 [==============================] - ETA: 0s - loss: 2.0093 - accuracy: 0.8728\n",
      "Epoch 00028: val_loss improved from 2.28055 to 2.19723, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 102s 815ms/step - loss: 2.0093 - accuracy: 0.8728 - val_loss: 2.1972 - val_accuracy: 0.7823\n",
      "Epoch 29/1000\n",
      "125/125 [==============================] - ETA: 0s - loss: 1.9186 - accuracy: 0.8919\n",
      "Epoch 00029: val_loss improved from 2.19723 to 2.17186, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 104s 832ms/step - loss: 1.9186 - accuracy: 0.8919 - val_loss: 2.1719 - val_accuracy: 0.7596\n",
      "Epoch 30/1000\n",
      "125/125 [==============================] - ETA: 0s - loss: 1.8824 - accuracy: 0.8917\n",
      "Epoch 00030: val_loss did not improve from 2.17186\n",
      "125/125 [==============================] - 113s 908ms/step - loss: 1.8824 - accuracy: 0.8917 - val_loss: 2.2281 - val_accuracy: 0.7506\n",
      "Epoch 31/1000\n",
      "125/125 [==============================] - ETA: 0s - loss: 1.8970 - accuracy: 0.8710\n",
      "Epoch 00031: val_loss improved from 2.17186 to 2.13534, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 111s 886ms/step - loss: 1.8970 - accuracy: 0.8710 - val_loss: 2.1353 - val_accuracy: 0.7574\n",
      "Epoch 32/1000\n",
      "125/125 [==============================] - ETA: 0s - loss: 1.7775 - accuracy: 0.9131\n",
      "Epoch 00032: val_loss improved from 2.13534 to 2.08385, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 111s 889ms/step - loss: 1.7775 - accuracy: 0.9131 - val_loss: 2.0838 - val_accuracy: 0.7755\n",
      "Epoch 33/1000\n",
      "125/125 [==============================] - ETA: 0s - loss: 1.7445 - accuracy: 0.9038\n",
      "Epoch 00033: val_loss improved from 2.08385 to 2.02504, saving model to ModelWeights.h5\n",
      "125/125 [==============================] - 104s 828ms/step - loss: 1.7445 - accuracy: 0.9038 - val_loss: 2.0250 - val_accuracy: 0.7868\n",
      "Epoch 34/1000\n",
      " 57/125 [============>.................] - ETA: 1:35 - loss: 1.7086 - accuracy: 0.9172"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-ad6f4ea5acc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m model_history = model.fit(x_train, y_train, batch_size = batch_size,\n\u001b[0;32m     10\u001b[0m              \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m       callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#prevents overfitting and saves models every time the validation loss improves\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=10, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint('ModelWeights.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 2, mode = 'min')\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "model = get_conv_model()\n",
    "model_history = model.fit(x_train, y_train, batch_size = batch_size,\n",
    "             epochs = epochs, \n",
    "      callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_paths = ['{i}' for i in range(6)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{i}', '{i}', '{i}', '{i}', '{i}', '{i}']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
